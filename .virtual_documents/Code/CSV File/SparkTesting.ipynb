


import plotly.io as pio
pio.renderers.default = "notebook+pdf"


import pandas as pd
import numpy as np

import plotly.express as px
from plotly.subplots import make_subplots
import plotly.graph_objects as go

from sklearn.impute import SimpleImputer
from sklearn.model_selection import StratifiedShuffleSplit
from typing import List
from sklearn.preprocessing import RobustScaler,StandardScaler
from sklearn.decomposition import PCA
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score,confusion_matrix
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import precision_recall_fscore_support

from imblearn.over_sampling import SMOTE, ADASYN
from imblearn.over_sampling import RandomOverSampler

from plotly.offline import plot, iplot, init_notebook_mode
init_notebook_mode(connected=True)

import warnings

warnings.filterwarnings('ignore')


df=pd.read_csv("./Data/kag_risk_factors_cervical_cancer.csv")
df.head()


target = 'Biopsy'


df=df.drop_duplicates()
df.info()


df = df.replace('?', np.nan)

print("Check all Nan counts")
df.isnull().sum()


df = df.apply(pd.to_numeric, errors='coerce')
df = df.fillna(df.median())

print("Check all Nan counts")
df.isnull().sum()





import findspark
findspark.init()
findspark.find()

from pyspark.sql import SparkSession
from pyspark.conf import SparkConf
conf = SparkConf().setAppName("MyApp").set("spark.executor.cores", "2")
spark = SparkSession.builder.config(conf=conf).getOrCreate()






from sklearn.model_selection import train_test_split
from pyspark.ml.classification import LogisticRegression as LogisticRegression_Spark
from pyspark.ml.classification import DecisionTreeClassifier as DecisionTreeClassifier_Spark
from pyspark.ml.classification import RandomForestClassifier as RandomForestClassifier_Spark
from pyspark.ml.classification import GBTClassifier as GBTClassifier_Spark
from pyspark.ml.classification import LinearSVC as LinearSVC_Spark
from pyspark.ml.classification import NaiveBayes as NaiveBayes_Spark
from pyspark.ml.classification import FMClassifier as FMClassifier_Spark
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
import timeit

def training_loop(df, performance_metrics):
    # Split data into training and testing dataset
    X = df.drop([target], axis=1)
    y = df[target].copy()
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y, shuffle=True)

    # Apply ADASYN only on the training data
    adasyn = ADASYN()
    X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)

    # Create Spark dataframes for training and testing sets
    df_spark_train = spark.createDataFrame(pd.concat([X_train_resampled, y_train_resampled], axis=1))
    df_spark_test = spark.createDataFrame(pd.concat([X_test, y_test], axis=1))

    # Define model list
    model_list = [("LogRegression", LogisticRegression_Spark(featuresCol="features", labelCol=target)),
                  ("DecTree", DecisionTreeClassifier_Spark(featuresCol="features", labelCol=target)),
                  ("RandomForrest", RandomForestClassifier_Spark(featuresCol="features", labelCol=target)),
                  ("GBTClassifier", GBTClassifier_Spark(featuresCol="features", labelCol=target)),
                  ("LinearSVC", LinearSVC_Spark(featuresCol="features", labelCol=target)),
                  ("NaiveBayes", NaiveBayes_Spark(featuresCol="features", labelCol=target)),
                  ("FMClassifier", FMClassifier_Spark(featuresCol="features", labelCol=target))]

    # Prepare data for model training
    assembler = VectorAssembler(inputCols=df_spark_train.columns[:-1], outputCol='features')
    df_spark_train = assembler.transform(df_spark_train).select('features', target)
    df_spark_test = assembler.transform(df_spark_test).select('features', target)

    # Output columns for output dataframe
    cols_name = ['Name'] + performance_metrics + ['time(s)']
    performance_df_spark = pd.DataFrame(columns=cols_name)

    # Handle all normal models
    for model_name, model in model_list:
        start_time = timeit.default_timer()
        trained_model = model.fit(df_spark_train)
        predictions = trained_model.transform(df_spark_test)

        temp = [model_name]
        for metric in performance_metrics:
            evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol=target, metricName=metric)
            temp.append(evaluator.evaluate(predictions))
            
        end_time = timeit.default_timer() - start_time
        temp.append(end_time)
        
        performance_df_spark.loc[len(performance_df_spark)] = temp
        print(trained_model, end_time)
    
    return performance_df_spark






performance_metrics=['accuracy','precisionByLabel','recallByLabel','f1']
cols_name=['Name']
for  p in performance_metrics:
    cols_name.append(p)
cols_name.append('time(s)')
performance_df_spark = pd.DataFrame(columns = cols_name)

for _ in range(10):
    performance_df_spark = pd.concat([performance_df_spark, training_loop(df, performance_metrics)], ignore_index=True)



avg_df=performance_df_spark.groupby('Name',as_index=False)[performance_metrics].mean()
acc_comparison = px.bar(avg_df, x="Name",
                        y=performance_metrics,
                        barmode="group")
acc_comparison.show()


px.bar(performance_df_spark.groupby('Name',as_index=False)['time(s)'].mean(),x="Name",y=["time(s)"],color='Name')



performance_df_spark.groupby('Name',as_index=False).mean()



performance_df_spark



